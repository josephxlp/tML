{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62d686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from uvars import givemesomecredit_dir,tML_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8ded7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(tML_dir)\n",
    "from automl import agluon_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305a6bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "presents = ['medium_quality', 'good_quality','high_quality','best_quality']\n",
    "problem_type = \"binary\" # ‘binary’, ‘multiclass’, ‘regression’, ‘quantile  \n",
    "eval_metric = \"roc_auc\"\n",
    "time_limit = 60 * 2#10 # 10 minutes \n",
    "verbosity = 1 \n",
    "sample_weight = 'auto_weight'\n",
    "expname = 'ag_def' # ag_tun\n",
    "agluon_dir = os.path.join('submit', 'agluon',expname)\n",
    "os.makedirs(agluon_dir, exist_ok=True)\n",
    "\n",
    "presents_tun = ['high_quality','best_quality']\n",
    "presents_def = ['medium_quality', 'good_quality','high_quality','best_quality'] \n",
    "\n",
    "exp_names = ['ag_def', 'ag_tun']\n",
    "exp_presents = [presents_def,presents_tun]\n",
    "assert len(exp_names) == len(exp_presents), 'list of iterators do not match'\n",
    "\n",
    "\n",
    "datapth = os.path.join(givemesomecredit_dir)\n",
    "train = pd.read_csv(os.path.join(datapth, 'cstraining.csv'))\n",
    "test = pd.read_csv(os.path.join(datapth, 'cstest.csv'))\n",
    "ss = pd.read_csv(os.path.join(datapth, 'cssampleentry.csv'))\n",
    "data = [train, test]\n",
    "for df in data:\n",
    "    df.rename(columns={'Unnamed: 0':'Id'}, inplace=True)\n",
    "\n",
    "del df \n",
    "tcol = 'SeriousDlqin2yrs'\n",
    "fcols = train.drop(['Id',tcol], axis=1).columns.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[fcols], train[tcol], test_size=0.1, stratify=train[tcol])\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "valid_data = pd.concat([X_test, y_test],axis=1)\n",
    "train_data.shape, valid_data.shape\n",
    "\n",
    "print(f\"Unique classes: {list(train_data[tcol].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c56001",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(exp_names)) :\n",
    "    expname = exp_names[i]\n",
    "    presents = exp_presents[i]\n",
    "    print(f'{expname} @{presents}')\n",
    "    agluon_dir = os.path.join(datapth,'submit', 'agluon',expname)\n",
    "    os.makedirs(agluon_dir, exist_ok=True)\n",
    "    agluon_pipeline(\n",
    "        expname=expname,\n",
    "        agluon_dir=agluon_dir,\n",
    "        presents=presents,\n",
    "        problem_type=problem_type,\n",
    "        eval_metric=eval_metric,\n",
    "        verbosity=verbosity,\n",
    "        sample_weight=sample_weight,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        test=test,\n",
    "        fcols=fcols,\n",
    "        tcol=tcol,\n",
    "        time_limit=time_limit,\n",
    "        calibrate_decision_threshold=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec8dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
